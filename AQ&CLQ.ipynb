{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onurozansunger/ADM-HW5-Group2/blob/main/AQ%26CLQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithmic Question"
      ],
      "metadata": {
        "id": "Hkd6rmiYCFMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART A"
      ],
      "metadata": {
        "id": "-2GtUa_p49H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "input_text = \"\"\"14 10 2\n",
        "SWM VOL ATH VOL VOL BSK HCK BSK SWM BSK\n",
        "1\n",
        "BSK 98\n",
        "2\n",
        "ATH 14\n",
        "3\n",
        "HCK 82\n",
        "4\n",
        "HCK 9\n",
        "5\n",
        "FTB 90\n",
        "6\n",
        "ATH 52\n",
        "7\n",
        "HCK 95\n",
        "8\n",
        "TEN 85\n",
        "9\n",
        "RGB 46\n",
        "10\n",
        "SWM 16\n",
        "11\n",
        "VOL 32\n",
        "12\n",
        "SOC 41\n",
        "13\n",
        "SWM 59\n",
        "14\n",
        "SWM 34\n",
        "\"\"\"\n",
        "\n",
        "# Split the input text into lines\n",
        "lines = input_text.strip().split('\\n')\n",
        "\n",
        "# Extract N, M, and S from the first line\n",
        "number_of_athletes, number_of_selected_athletes, number_of_skills = map(int, lines[0].split())\n",
        "\n",
        "# Extract the set of required skills\n",
        "required_skills = lines[1].split()\n",
        "\n",
        "# Initialize dictionary for maximum proficiency\n",
        "max_proficiency = {skill: 0 for skill in required_skills}\n",
        "\n",
        "# Process each athlete's information and update maximum proficiency\n",
        "athlete_info = []\n",
        "for i in range(2, len(lines), 2):\n",
        "    athlete_id = int(lines[i])\n",
        "    current_skill, proficiency = lines[i + 1].split()\n",
        "    proficiency = int(proficiency)\n",
        "\n",
        "    # Check if the skill is in the set of required skills\n",
        "    if current_skill in required_skills:\n",
        "        # Update maximum proficiency for the current skill\n",
        "        if proficiency > max_proficiency[current_skill]:\n",
        "            max_proficiency[current_skill] = proficiency\n",
        "\n",
        "        # Store athlete's information\n",
        "        athlete_info.append((athlete_id, current_skill, proficiency))\n",
        "\n",
        "# Sort athletes by proficiency in descending order\n",
        "athlete_info.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "# Select the top M athletes and calculate overall score\n",
        "selected_athletes = athlete_info[:number_of_selected_athletes]\n",
        "overall_score = sum(athlete[2] for athlete in selected_athletes)\n",
        "\n",
        "# Print the final result\n",
        "print(\"The maximum overall score for Team Rome is:\", overall_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tsQqwAspxEH",
        "outputId": "4bb3eb50-d495-4016-8c17-5ee4ec713d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum overall score for Team Rome is: 491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "input_text = \"\"\"14 10 2\n",
        "SWM VOL ATH VOL VOL BSK HCK BSK SWM BSK\n",
        "1\n",
        "BSK 98\n",
        "HCK 12\n",
        "2\n",
        "ATH 14\n",
        "VOL 1\n",
        "3\n",
        "HCK 82\n",
        "ATH 30\n",
        "4\n",
        "HCK 9\n",
        "SWM 27\n",
        "5\n",
        "FTB 90\n",
        "HCK 50\n",
        "6\n",
        "ATH 52\n",
        "RGB 80\n",
        "7\n",
        "HCK 95\n",
        "SWM 11\n",
        "8\n",
        "TEN 85\n",
        "RGB 7\n",
        "9\n",
        "RGB 46\n",
        "SWM 30\n",
        "10\n",
        "SWM 16\n",
        "BSK 12\n",
        "11\n",
        "VOL 32\n",
        "HCK 40\n",
        "12\n",
        "SOC 41\n",
        "FTB 12\n",
        "13\n",
        "SWM 59\n",
        "TEN 82\n",
        "14\n",
        "SWM 34\n",
        "VOL 20\n",
        "\"\"\"\n",
        "\n",
        "# Split the input text into lines\n",
        "lines = input_text.strip().split('\\n')\n",
        "\n",
        "# Extract N, M, and S from the first line\n",
        "number_of_athletes, number_of_selected_athletes, number_of_skills = map(int, lines[0].split())\n",
        "\n",
        "# Extract the set of required skills\n",
        "required_skills = lines[1].split()\n",
        "\n",
        "# Initialize dictionary for maximum proficiency\n",
        "max_proficiency = {skill: 0 for skill in required_skills}\n",
        "\n",
        "# Process each athlete's information and update maximum proficiency\n",
        "athlete_info = []\n",
        "for i in range(2, len(lines), S + 1):\n",
        "    athlete_id = int(lines[i])\n",
        "    skills = lines[i + 1:i + S + 1]\n",
        "\n",
        "    for skill_info in skills:\n",
        "        skill, proficiency = skill_info.split()\n",
        "        proficiency = int(proficiency)\n",
        "\n",
        "        # Check if the skill is in the set of required skills\n",
        "        if skill in required_skills:\n",
        "            # Update maximum proficiency for the current skill\n",
        "            if proficiency > max_proficiency[skill]:\n",
        "                max_proficiency[skill] = proficiency\n",
        "\n",
        "            # Store athlete's information\n",
        "            athlete_info.append((athlete_id, skill, proficiency))\n",
        "\n",
        "# Sort athletes by proficiency in descending order\n",
        "athlete_info.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "# Select the top M athletes and calculate overall score\n",
        "selected_athletes = athlete_info[:number_of_selected_athletes]\n",
        "overall_score = sum(athlete[2] for athlete in selected_athletes)\n",
        "\n",
        "# Print the final result\n",
        "print(\"The maximum overall score for Team Rome is:\", overall_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh38UM6b1kaZ",
        "outputId": "37282f00-605b-401b-e250-3101d5b3a396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum overall score for Team Rome is: 572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Complexity Analysis:\n",
        "\n",
        "Let's analyze the time complexity of the provided solution.\n",
        "\n",
        "Initialization of max_proficiency dictionary: This operation takes O(S) time since we iterate over the skills_required list (which has a maximum length of S).\n",
        "Processing candidates and updating maximum proficiency: In the worst case, we process N athletes, each with S skills. Therefore, this part has a time complexity of O(N * S).\n",
        "Sorting candidates: The sorting operation takes O(N * log(N)) time, where N is the number of athletes.\n",
        "Selecting top M candidates: This operation takes O(M) time.\n",
        "The overall time complexity can be expressed as O(S + N * S + N * log(N) + M), and in big O notation, we consider the dominant term, which is N * log(N). Therefore, the time complexity of the solution is O(N * log(N))."
      ],
      "metadata": {
        "id": "mbQAKBORuVmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT and Bard are calculating the Time complexity as the same as I found"
      ],
      "metadata": {
        "id": "Q09q52Jy3E6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exponential Time Complexity:\n",
        "\n",
        "The provided solution does not have an exponential time complexity. It is dominated by the sorting operation, which has a time complexity of O(N * log(N)).\n",
        "\n",
        "Polynomial-Time Version:\n",
        "\n",
        "The solution already has a polynomial time complexity, and there is no need for further optimization in this regard.\n",
        "\n",
        "Changing S to 1:\n",
        "\n",
        "If S is set to 1, the solution simplifies as each athlete has only one skill. In this case, the time complexity becomes O(N * log(N)) due to the sorting operation. The processing of skills within each athlete remains O(N), and the overall complexity is influenced more by the sorting step."
      ],
      "metadata": {
        "id": "VJSGEiKf3Nkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART B"
      ],
      "metadata": {
        "id": "7Je0owSn5Cgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Proof of NP-Completeness:\n",
        "\n",
        "The problem described can be shown to be NP-complete by reduction from the Hamiltonian Cycle Problem, which is a known NP-complete problem.\n",
        "\n",
        "Given an instance of the Hamiltonian Cycle Problem with a graph G=(V, E), construct an instance of the new problem as follows:\n",
        "\n",
        "Set X = V.\n",
        "Define T as the set of all possible skills.\n",
        "For each edge (u, v) in E, add a corresponding edge between the nodes u and v in the new problem with weight 1.\n",
        "Now, finding a team X' in the new problem with minimum effort E_c(V') that covers all skills in T is equivalent to finding a Hamiltonian Cycle in the original graph G. The effort to work together, represented by the weight of edges in X', corresponds to the length of the Hamiltonian Cycle.\n",
        "\n",
        "Since the Hamiltonian Cycle Problem is NP-complete, the new problem is also NP-complete."
      ],
      "metadata": {
        "id": "O2qgcvQC5G3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Heuristic for Approximation:\n",
        "\n",
        "A simple heuristic for approximating the best solution is the Minimum Spanning Tree (MST) heuristic:\n",
        "\n",
        "1.Construct the complete graph G=(V, E) where each node corresponds to an individual and each edge has a weight equal to the effort required to work well together.\n",
        "\n",
        "2.Find the Minimum Spanning Tree T of G.\n",
        "\n",
        "3.Select the nodes corresponding to the vertices of T as the team X'.\n",
        "\n",
        "This heuristic is efficient and provides a reasonable approximation for the minimum effort to work together. However, it may not always yield the optimal solution."
      ],
      "metadata": {
        "id": "qkJLJxM75PLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Function MST_Heuristic(X, G):\n",
        "    # X is the set of individuals (nodes), G is the complete graph with weights representing efforts\n",
        "\n",
        "    # Initialize an empty set to store the selected nodes\n",
        "    selected_nodes = Set()\n",
        "\n",
        "    # Add an arbitrary starting node to the set\n",
        "    starting_node = arbitrary_node(X)\n",
        "    selected_nodes.add(starting_node)\n",
        "\n",
        "    # Initialize an empty priority queue to store edges sorted by weight\n",
        "    edge_queue = PriorityQueue()\n",
        "\n",
        "    # Add all edges connected to the starting node to the priority queue\n",
        "    for edge in edges_connected_to(starting_node, G):\n",
        "        edge_queue.add(edge)\n",
        "\n",
        "    # While not all nodes are selected\n",
        "    while len(selected_nodes) < len(X):\n",
        "        # Get the edge with the minimum weight from the priority queue\n",
        "        min_edge = edge_queue.pop_min()\n",
        "\n",
        "        # Add the target node of the edge to the selected nodes set\n",
        "        selected_nodes.add(min_edge.target_node)\n",
        "\n",
        "        # Add all edges connected to the newly selected node to the priority queue\n",
        "        for edge in edges_connected_to(min_edge.target_node, G):\n",
        "            edge_queue.add(edge)\n",
        "\n",
        "    return selected_nodes\n",
        "\n",
        "# Call the MST_Heuristic function with the set of individuals (X) and the complete graph (G)\n",
        "selected_team = MST_Heuristic(X, G)\n"
      ],
      "metadata": {
        "id": "Q5hsFnYU5h9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Time Complexity of the Heuristic:\n",
        "\n",
        "The time complexity of the MST heuristic is dominated by the step of finding the Minimum Spanning Tree. Various algorithms, such as Prim's or Kruskal's algorithm, can be employed to find the MST.\n",
        "\n",
        "Assuming the graph has N nodes, the time complexity of finding the MST using Prim's algorithm is O(N^2) with an adjacency matrix representation and O(E * log(N)) with an adjacency list representation, where E is the number of edges.\n",
        "\n",
        "In conclusion, the time complexity of the heuristic is primarily determined by the MST algorithm chosen and the representation of the graph."
      ],
      "metadata": {
        "id": "2HiTDDEA5kI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Command Line Question (CLQ)"
      ],
      "metadata": {
        "id": "lK4hhCSlCDfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Script"
      ],
      "metadata": {
        "id": "a8BtJkcrCfl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# Analyze betweenness centrality and node degrees from graph_analysis.txt\n",
        "\n",
        "echo \"Analyzing betweenness centrality and node degrees from graph_analysis.txt\"\n",
        "\n",
        "# Question 1\n",
        "\n",
        "# Display top 5 nodes by betweenness centrality\n",
        "echo \"Top 5 nodes by betweenness centrality:\"\n",
        "sort -k2 -nr graph_analysis.txt | head -5\n",
        "echo \"\" # Add a blank line for better readability\n",
        "\n",
        "# Question 2\n",
        "\n",
        "# Calculate and display degree variation among nodes (Answer to Question 2)\n",
        "echo \"Degree variation among nodes:\"\n",
        "awk '{sum += $3; sqsum += $3 * $3; count++} END {print \"Average Degree: \" sum/count; print \"Standard Deviation: \" sqrt(sqsum/count - (sum/count)^2)}' graph_analysis.txt\n",
        "echo \"\" # Add a blank line for better readability\n",
        "\n",
        "# Question 3\n",
        "\n",
        "# Use Python to calculate average shortest path length from the saved graph\n",
        "echo \"Calculating average shortest path length using Python:\"\n",
        "python3 - <<EOF\n",
        "import pickle\n",
        "import networkx as nx\n",
        "\n",
        "# Load the graph from the pickle file\n",
        "with open('citation_graph.pkl', 'rb') as file:\n",
        "    citation_graph = pickle.load(file)\n",
        "\n",
        "# Method 1: Using NetworkX's average_shortest_path_length function\n",
        "try:\n",
        "    avg_path_length_nx = nx.average_shortest_path_length(citation_graph)\n",
        "    print(f\"Average Shortest Path Length (NetworkX method): {avg_path_length_nx}\")\n",
        "except nx.NetworkXError:\n",
        "    print(\"Graph is not connected, average shortest path not computable using NetworkX method.\")\n",
        "\n",
        "# Method 2: Using breadth-first search (BFS) for each node\n",
        "def calculate_avg_shortest_path_bfs(graph):\n",
        "    total_length, total_paths = 0, 0\n",
        "    for source in graph:\n",
        "        path_lengths = nx.single_source_shortest_path_length(graph, source)\n",
        "        total_length += sum(path_lengths.values())\n",
        "        total_paths += len(path_lengths) - 1  # Exclude the path to the source itself\n",
        "    return total_length / total_paths if total_paths > 0 else 0\n",
        "\n",
        "avg_path_length_bfs = calculate_avg_shortest_path_bfs(citation_graph)\n",
        "print(f\"Average Shortest Path Length (BFS method): {avg_path_length_bfs}\")\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "59zL1mZ7CaNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview"
      ],
      "metadata": {
        "id": "k4HL8FjKFRVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top 5 nodes by betweenness centrality (Answer to Question 1)\n",
        "echo \"Top 5 nodes by betweenness centrality:\"\n",
        "sort -k2 -nr graph_analysis.txt | head -5\n",
        "echo \"\" # Add a blank line for better readability\n"
      ],
      "metadata": {
        "id": "7tTJsXWoFU4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Betweenness Centrality Analysis: The script sorts the data in graph_analysis.txt by the betweenness centrality values (second column) in descending order and displays the top 5 nodes. This addresses the question about identifying important connector nodes in the graph.\n",
        "2. sort -k2 -nr sorts the lines based on the second column (betweenness centrality) in numerical and reverse order.\n",
        "3. head -5 outputs the top 5 lines from the sorted list.\n",
        "4. An additional echo \"\" command is used to insert a blank line for better readability in the output."
      ],
      "metadata": {
        "id": "_8296irmFZ9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display degree variation among nodes (Answer to Question 2)\n",
        "echo \"Degree variation among nodes:\"\n",
        "awk '{sum += $3; sqsum += $3 * $3; count++} END {print \"Average Degree: \" sum/count; print \"Standard Deviation: \" sqrt(sqsum/count - (sum/count)^2)}' graph_analysis.txt\n",
        "echo \"\" # Add a blank line for better readability\n"
      ],
      "metadata": {
        "id": "iDj6Vwv_FlMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Degree Variation Analysis: This part calculates and displays the average degree and standard deviation of node degrees in the graph, answering the question about how the degree of citation varies among graph nodes.\n",
        "2. awk is used for this calculation. It processes each line, summing up the degrees (third column in the file) and their squares.\n",
        "3. The END block of the awk script calculates the average and standard deviation based on the accumulated sums."
      ],
      "metadata": {
        "id": "5wC-DtmzFn9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Python to calculate average shortest path length from the saved graph (Answer to Question 3)\n",
        "echo \"Calculating average shortest path length using Python:\"\n",
        "python3 - <<EOF\n"
      ],
      "metadata": {
        "id": "aWygS4ZRFuk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The script then moves on to calculate the average shortest path length using an embedded Python script. This addresses the question regarding the average length of the shortest path among nodes.\n",
        "2. The Python code is embedded directly within the shell script using a here document (<<EOF ... EOF). This allows the execution of a Python script within a shell script."
      ],
      "metadata": {
        "id": "UoozJXWxF88J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import networkx as nx\n",
        "...\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "0ARhYSOMGFXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Script for Shortest Path Calculation:\n"
      ],
      "metadata": {
        "id": "xNEbVn2ZGK1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The Python script starts by importing necessary modules: pickle for loading the saved graph and networkx for graph analysis.\n",
        "2. It loads the citation graph from a file (citation_graph.pkl) that was previously saved using Python's pickle module.\n",
        "3. Two methods are used to calculate the average shortest path length:\n",
        "\n",
        "NetworkX Method: Uses nx.average_shortest_path_length, suitable for connected graphs.\n",
        "\n",
        "Breadth-First Search (BFS) Method: A custom method to calculate the average shortest path length even if the graph is not connected. It uses nx.single_source_shortest_path_length for each node to find the shortest path lengths to all reachable nodes and then calculates the average.\n",
        "\n",
        "4. The use of both methods provides flexibility: the NetworkX method is efficient for connected graphs, while the BFS method ensures a fallback in case the graph is not fully connected."
      ],
      "metadata": {
        "id": "P4bYUgWhGVKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "UWFG-JJjHB2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script effectively combines command line operations with Python scripting to perform complex graph analysis tasks. By using sort, awk, and Python within a Bash script, it efficiently answers specific graph-theoretical questions about a citation network."
      ],
      "metadata": {
        "id": "bzJDPe1qHDdF"
      }
    }
  ]
}